#framework name
name = "rms-model"

#mail configurations
mail{
  host = "smtp.qq.com"
  port = 25
  user = "bwtechwarn@jointwisdom.cn"
  password = "abc/123"
  auth = true
  from="bwtechwarn@jointwisdom.cn"
  #multi receiver, such as ["a1@b.com","a2@b.com"]
  to=["xnzhang@jointwisdom.cn"]
}

#assembly的存放目录的绝对路径
assemblies-dir = "/hadoop/1/bi_rms_v2/models/pred/assemblies/"
#所有assembly的配置信息
assemblies = [
  {
    name = "micro-pred-longterm"
    index = 1
    #options ["cleaner","model"]
    type = "model"
    jar-name = "rms-ab-micro-pred-longterm-assembly-1.0.jar"
    class-name = "cn.jw.rms.ab.pred.longterm.Predictor"
    enable = true
  },
  {
    name = "micro-pred-shortterm"
    index = 2
    #options ["cleaner","model"]
    type = "model"
    jar-name = "rms-ab-micro-pred-shortterm-assembly-1.0.jar"
    class-name = "cn.jw.rms.ab.pred.shortterm.Predictor"
    enable = true
  },
  {
    name = "micro-pred-combine"
    index = 3
    #options ["cleaner","model"]
    type = "model"
    jar-name = "rms-ab-micro-pred-combine-assembly-1.0.jar"
    class-name = "cn.jw.rms.ab.pred.combine.Predictor"
    enable = true
  },
  {
    name = "micro-pred-fix"
    index = 4
    #options ["cleaner","model"]
    type = "model"
    jar-name = "rms-ab-micro-pred-fix-assembly-1.0.jar"
    class-name = "cn.jw.rms.ab.pred.fix.Predictor"
    enable = true
  },
  {
    name = "micro-pred-sum-seg"
    index = 5
    #options ["cleaner","model"]
    type = "model"
    jar-name = "rms-ab-micro-pred-sum-assembly-1.0.jar"
    class-name = "cn.jw.rms.ab.pred.sum.Predictor"
    enable = true
  }
]

#assembly的参数配置
parameters = [
  {
    #(必填)assembly的唯一名称, 标识该参数列表属于哪个assembly
    name = "micro-pred-longterm"
    #以下就为具体的参数
    #(必填)数据源所在目录
    hadoop-host= "hdfs://ns1"
    #(必填)数据源所在目录
    segbkdailysum-dir="hdfs://ns1/p/bw/bi/rms/seg_bk_daily_sum/"
    segpredconf-dir = "hdfs://ns1/p/bw/bi/rms/seg_pred_conf/*"
    holidays-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_holidays/*"
    hotel-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_hotel/*"
    season-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_season/*"
    #(必填)处理后数据保存目录
    dist-dir="hdfs://ns1/p/bw/bi/rms/pred_longterm/"
    #(必填)清洗开始日期,指定日期时,实际使用(fc-date - 1)的日期
    #default is "now"
    fc-date = "2015-02-16"
    default-fc-days = 320
    #必须为365的倍数
    default-hist-days = 960
    common-htlcd = "BW00000001"
    #default is "all"
    fc-htlcd = "all"
    field-splitter = "#"
    #(必填)pairRDD重新分区的个数, 一般为cpu核数
    pairRDD-repartition-num = 0
    #(必填)普通RDD重新分区的个数, 视情况而定, 一般为cpu核数
    RDD-repartition-num = 1
    #(必填)是否将清洗后数据保存到上面的保存目录
    save-result-to-file = true
    using-prevStepRDD=false
    test-open = true
    test-segbkdailysum-dir = "hdfs://ns1/p/bw/bi/rms/seg_bk_daily_sum/dt=20160316"
  },
  {
    #(必填)assembly的唯一名称, 标识该参数列表属于哪个assembly
    name = "micro-pred-shortterm"
    #以下就为具体的参数
    #(必填)数据源所在目录
    hadoop-host= "hdfs://ns1"
    segbkdailysum-dir="hdfs://ns1/p/bw/bi/rms/seg_bk_daily_sum/"
    segpredconf-dir = "hdfs://ns1/p/bw/bi/rms/seg_pred_conf/*"
    holidays-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_holidays/*"
    hotel-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_hotel/*"
    season-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_season/*"
    #(必填)处理后数据保存目录
    dist-dir="hdfs://ns1/p/bw/bi/rms/pred_shortterm/"
    #(必填)清洗开始日期,指定日期时,实际使用(fc-date - 1)的日期
    #default is "now"
    fc-date = "2015-02-16"
    default-fc-days = 320
    common-htlcd = "BW00000001"
    #default is "all"
    fc-htlcd = "all"
    field-splitter = "#"
    #(必填)pairRDD重新分区的个数, 一般为cpu核数
    pairRDD-repartition-num = 0
    #(必填)普通RDD重新分区的个数, 视情况而定, 一般为cpu核数
    RDD-repartition-num = 1
    #(必填)是否将清洗后数据保存到上面的保存目录
    save-result-to-file = true
    using-prevStepRDD=false
    test-open = true
    test-segbkdailysum-dir = "hdfs://ns1/p/bw/bi/rms/seg_bk_daily_sum/dt=20160316"
  },
  {
    #(必填)assembly的唯一名称, 标识该参数列表属于哪个assembly
    name = "micro-pred-combine"
    #以下就为具体的参数
    #(必填)数据源所在目录
    hadoop-host= "hdfs://ns1"
    #(必填)数据源所在目录
    longterm-result-dir = "hdfs://ns1/p/bw/bi/rms/pred_longterm"
    shortterm-result-dir = "hdfs://ns1/p/bw/bi/rms/pred_shortterm"
    holidays-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_holidays/*"
    hotel-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_hotel/*"
    season-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_season/*"
    segpredconf-dir = "hdfs://ns1/p/bw/bi/rms/seg_pred_conf/*"
    #(必填)处理后数据保存目录
    dist-dir = "hdfs://ns1/p/bw/bi/rms/pred_combine"
    #(必填)清洗开始日期
    #default is "now"
    fc-date = "2015-02-16"
    default-fc-days = 320
    #必须为365的倍数
    common-htlcd = "BW00000001"
    #default is "all"
    fc-htlcd = "all"
    field-splitter = "#"
    #(必填)pairRDD重新分区的个数, 一般为cpu核数
    pairRDD-repartition-num = 0
    #(必填)普通RDD重新分区的个数, 视情况而定, 一般为cpu核数
    RDD-repartition-num = 0
    #(必填)是否将清洗后数据保存到上面的保存目录
    save-result-to-file = true
    using-prevStepRDD=false
  },
  {
    #(必填)assembly的唯一名称, 标识该参数列表属于哪个assembly
    name = "micro-pred-fix"
    #以下就为具体的参数
    #(必填)数据源所在目录
    hadoop-host= "hdfs://ns1"
    #(必填)数据源所在目录
    combine-result-dir = "hdfs://ns1/p/bw/bi/rms/pred_combine"
    inventory-dir = "hdfs://ns1/p/bw/bi/rms/rms_inventory"
    segpredconf-dir = "hdfs://ns1/p/bw/bi/rms/seg_pred_conf/*"
    hotel-dir = "hdfs://ns1/p/bw/bi/rms/rms_ref_hotel/*"
    #(必填)处理后数据保存目录
    dist-dir = "hdfs://ns1/p/bw/bi/rms/pred_fix"
    #(必填)清洗开始日期
    #default is "now"
    fc-date = "2015-02-16"
    default-fc-days = 320
    common-htlcd = "BW00000001"
    #default is "all"
    fc-htlcd = "all"
    field-splitter = "#"
    #(必填)pairRDD重新分区的个数, 一般为cpu核数
    pairRDD-repartition-num = 0
    #(必填)普通RDD重新分区的个数, 视情况而定, 一般为cpu核数
    RDD-repartition-num = 0
    #(必填)是否将清洗后数据保存到上面的保存目录
    save-result-to-file = true
    using-prevStepRDD=false
  },
  {
    name = "micro-pred-sum-seg"
    matrix_input_path = "hdfs://ns1/p/bw/bi/rms/pred_fix"
    fc_price_input_path = "hdfs://ns1/p/bw/bi/rms/pred_avg_price"
    field_seporator = "#"
    inventory_input_path = "hdfs://ns1/p/bw/bi/rms/rms_inventory"
    output_path = "hdfs://ns1/p/bw/bi/rms/rms_forecast_detail"
    pairRDD-repartition-num = "-1"
    RDD-repartition-num = "-1"
    save-result-to-file = true
    accepted_normaldata_rate = 1
    hdfsHost = "hdfs://ns1"
    fc_date="2015-02-16"
    default-fc-days = 320
    test-open = true
    test_fc_price_input_path = ""
  }
]