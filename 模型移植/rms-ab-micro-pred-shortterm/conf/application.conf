#(必填)assembly的唯一名称, 标识该参数列表属于哪个assembly
name = "micro-pred-shortterm"
#以下就为具体的参数
#(必填)数据源所在目录
hadoop-host= "hdfs://ns1"
#(必填)数据源所在目录
segbkdailysum-dir = "./testdata/seg_bk_daily_sum/"
predconf-dir = "./testdata/seg_pred_conf/"
hotel-dir = "./testdata/rms_ref_hotel"
specialdays-dir = "./testdata/rms_ref_holidays/"
season-dir = "./testdata/rms_ref_season/"
#(必填)处理后数据保存目录
dist-dir = "./testdata/dist"

#(必填)清洗开始日期
#default is "now"
fc-date = "2016-08-31"
common-htlcd = "BW00000001"
#default is "all"
fc-htlcd = "all"
field-splitter = "#"
#(必填)pairRDD重新分区的个数, 一般为cpu核数
pairRDD-repartition-num = 1
#(必填)普通RDD重新分区的个数, 视情况而定, 一般为cpu核数
RDD-repartition-num = 1
#(必填)是否将清洗后数据保存到上面的保存目录
save-result-to-file = true
checkpoint-num = 200
checkpoint-dir = "/tmp"
#checkpoint-num = 100
#checkpoint-dir = "hdfs://ns1/p/bw/bi/rms/spark_checkpoint"
using-prevStepRDD=false
hist-enable = true
hist-segbkdailysum-dir = "./testdata/seg_bk_daily_sum/"
#当test-open=true时, 作为历史数据的开始日期
hist-start="2015-01-01"
#当test-open=true时, 作为历史数据的结束日期
hist-end="2015-12-31"
#当test-open=false时, 作为计算历史数据开始日期的天数
default-hist-days = 239
#用提前几列的数据预测
m = 3
#当某个tag某预测列的历史数据不满足要求时,使用的w权重
# the count of w should be m + 1
singular-w = "0.3#0.3#0.3#0"
# options ["weekday","weekendOrNot","noWeekday","sameTag"]
season-weekday-tag-type = "sameTag"
#1:Mon, 2:Tue, 3:Wed, 4:Thu, 5:Fri, 6:Sat, 7:Sun
weekend-days = [5,6,7]
#if fc-type="daily" then here is days
fc-days = 14
matrix-columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,22,29,36,43,57,71,85,119,147,175,203,231,259,287,315,343,365]
#true or false
fault-tolerance = true
print-w = false
knn{
  k = 100
}
seg-type="FIT_TOTAL"